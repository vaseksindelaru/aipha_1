# shadow/config_shadow.yaml
shadow:
  # Rutas para el almacenamiento de datos del sistema Shadow
  storage_path: './shadow_storage'      # Base para todos los datos del shadow
  vector_db_path: './shadow_storage/vector_db' # Ruta específica para la base de datos vectorial ChromaDB
  
  # Configuración de la base de datos vectorial (ChromaDB)
  collection_name: 'aipha_shadow_collection' # Nombre de la colección donde se guardarán los documentos
  embedding_model: 'all-MiniLM-L6-v2'         # Modelo de SentenceTransformer para crear embeddings

  # Configuración de las consultas
  query_n_results: 5                           # Número máximo de documentos a recuperar como contexto

  # Configuración de los LLMs (Modelos de Lenguaje Grande) disponibles
  available_llms:
    openai:
      model: 'gpt-3.5-turbo'      # Modelo específico de OpenAI a usar
    gemini:
      model: 'gemini-2.5-pro'          # Modelo específico de Google Gemini a usar
    # claude:                         # Ejemplo para futuras expansiones
    #   model: 'claude-3-opus-20240229'
  
  # LLM por defecto para las consultas si no se especifica con --llm
  default_llm: 'gemini'

  # Configuración de la sincronización con el repositorio principal
  sync:
    source_path: '../'                # Ruta al directorio del proyecto Aipha principal
    # Opcionales para una lógica de sincronización más avanzada:
    # file_extensions: ['.py', '.yaml', '.md']   # Tipos de archivo a indexar
    # ignore_dirs: ['.git', '__pycache__', 'node_modules'] # Directorios a excluir del escaneo